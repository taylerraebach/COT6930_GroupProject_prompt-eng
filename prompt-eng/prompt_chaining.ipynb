{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Chaining Prompting\n",
    "\n",
    "Prompt Chaining refers to a technique in prompt engineering where multiple prompts are used in a sequence, with each subsequent prompt building on the output of the previous one. This process allows the model to refine its understanding, reasoning, and responses step by step, enabling it to handle more complex tasks that require multiple stages of reasoning or context.\n",
    "\n",
    "In other words, instead of generating a single response based on a single prompt, the model iteratively refines its answer by receiving intermediate outputs from previous prompts. This approach is particularly useful for tasks that involve multi-step reasoning, context accumulation, or tasks that need breaking down into smaller parts to ensure accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fzero_shot.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2', 'prompt': 'Rephrase or break down the following question into simpler steps:\\n\\nWhat is 5 * 6', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "Step 1 Output:\n",
      "Here's a step-by-step guide to calculate the answer:\n",
      "\n",
      "1. Start with the number 5.\n",
      "2. Multiply it by 6 (remember, multiplication means adding a certain number a certain number of times). Think of it like having 5 groups of 6 items in each group.\n",
      "\n",
      "To make it easier to understand, let's break it down further:\n",
      "   - Imagine you have 5 boxes, and in each box, you have 6 marbles.\n",
      "   - So, the total\n",
      "\n",
      "{'model': 'llama3.2', 'prompt': \"Using the following breakdown, compute the final answer:\\n\\nHere's a step-by-step guide to calculate the answer:\\n\\n1. Start with the number 5.\\n2. Multiply it by 6 (remember, multiplication means adding a certain number a certain number of times). Think of it like having 5 groups of 6 items in each group.\\n\\nTo make it easier to understand, let's break it down further:\\n   - Imagine you have 5 boxes, and in each box, you have 6 marbles.\\n   - So, the total\", 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "Final Output:\n",
      "It seems like we were going to calculate 5 x 6 together. \n",
      "\n",
      "The answer would be: \n",
      "5 x 6 = 30\n",
      "\n",
      "Total Time Taken: 51.80199999999999s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## RETRIEVAL AUGMENTED GENERATION (RAG)\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Initial User Query\n",
    "MESSAGE = \"What is 5 * 6\"\n",
    "\n",
    "#### (2) First Model Call: Reformulate the Question or Generate Step-by-Step Breakdown\n",
    "PROMPT_STEP_1 = f\"Rephrase or break down the following question into simpler steps:\\n\\n{MESSAGE}\"\n",
    "\n",
    "payload_1 = create_payload(target=\"ollama\",\n",
    "                           model=\"llama3.2\", \n",
    "                           prompt=PROMPT_STEP_1, \n",
    "                           temperature=1.0, \n",
    "                           num_ctx=100, \n",
    "                           num_predict=100)\n",
    "\n",
    "time_1, response_1 = model_req(payload=payload_1)\n",
    "print(f\"Step 1 Output:\\n{response_1}\\n\")\n",
    "\n",
    "#### (3) Second Model Call: Use the Reformulated Prompt for Final Answer\n",
    "PROMPT_STEP_2 = f\"Using the following breakdown, compute the final answer:\\n\\n{response_1}\"\n",
    "\n",
    "payload_2 = create_payload(target=\"ollama\",\n",
    "                           model=\"llama3.2\", \n",
    "                           prompt=PROMPT_STEP_2, \n",
    "                           temperature=1.0, \n",
    "                           num_ctx=100, \n",
    "                           num_predict=100)\n",
    "\n",
    "time_2, response_2 = model_req(payload=payload_2)\n",
    "print(f\"Final Output:\\n{response_2}\\n\")\n",
    "\n",
    "if time_2: print(f'Total Time Taken: {time_1 + time_2}s' if time_1 else f'Time Taken: {time_2}s')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
