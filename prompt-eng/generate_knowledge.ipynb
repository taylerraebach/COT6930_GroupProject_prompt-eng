{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Knowledge Prompting\n",
    "\n",
    "Generated Knowledge Prompting is a technique in prompt engineering where the model first generates relevant background knowledge about a query before attempting to answer it. This approach enhances the model's ability to reason and provide accurate responses by explicitly prompting it to recall or infer useful context.\n",
    "\n",
    "Instead of relying solely on its pre-trained knowledge, the model is first asked to generate foundational information related to the task. This generated knowledge is then incorporated into a second prompt to improve the quality and depth of the final response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fzero_shot.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2', 'prompt': 'Generate relevant background knowledge for the following question before solving it:\\n\\nWhat is 984 * log(2)', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 150}}\n",
      "Generated Knowledge:\n",
      "!!ERROR!! Request failed! You need to adjust prompt-eng/config with URL(http://localhost:11434/api/generate)\n",
      "\n",
      "{'model': 'llama3.2', 'prompt': 'Using the following knowledge, answer the question:\\n\\nKnowledge:\\n!!ERROR!! Request failed! You need to adjust prompt-eng/config with URL(http://localhost:11434/api/generate)\\n\\nQuestion: What is 984 * log(2)', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 200, 'num_predict': 150}}\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## GENERATE KNOWLEDGE PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Initial User Query\n",
    "MESSAGE = \"What is 984 * log(2)\"\n",
    "\n",
    "#### (2) First Model Call: Generate Background Knowledge\n",
    "PROMPT_KNOWLEDGE = f\"Generate relevant background knowledge for the following question before solving it:\\n\\n{MESSAGE}\"\n",
    "\n",
    "payload_knowledge = create_payload(target=\"ollama\",\n",
    "                                   model=\"llama3.2\", \n",
    "                                   prompt=PROMPT_KNOWLEDGE, \n",
    "                                   temperature=1.0, \n",
    "                                   num_ctx=200, \n",
    "                                   num_predict=150)\n",
    "\n",
    "time_1, knowledge_response = model_req(payload=payload_knowledge)\n",
    "print(f\"Generated Knowledge:\\n{knowledge_response}\\n\")\n",
    "\n",
    "#### (3) Second Model Call: Use the Generated Knowledge for Answering\n",
    "PROMPT_FINAL = f\"Using the following knowledge, answer the question:\\n\\nKnowledge:\\n{knowledge_response}\\n\\nQuestion: {MESSAGE}\"\n",
    "\n",
    "payload_final = create_payload(target=\"ollama\",\n",
    "                               model=\"llama3.2\", \n",
    "                               prompt=PROMPT_FINAL, \n",
    "                               temperature=1.0, \n",
    "                               num_ctx=200, \n",
    "                               num_predict=150)\n",
    "\n",
    "time_2, final_response = model_req(payload=payload_final)\n",
    "print(f\"Final Answer:\\n{final_response}\\n\")\n",
    "\n",
    "if time_2: print(f'Total Time Taken: {time_1 + time_2}s' if time_1 else f'Time Taken: {time_2}s')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
